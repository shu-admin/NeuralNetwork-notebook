{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuralNetwork .ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMwPZFh4y+OdnWBSwgG4usW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shu-admin/NeuralNetwork-notebook/blob/main/NeuralNetwork_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hx9apGpshHOC",
        "outputId": "919f2a8b-4f12-44ed-f0bb-cab9875352f1"
      },
      "source": [
        "! pip3 install torch==1.9.0+cu102 torchvision==0.10.0+cu102 torchaudio===0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: torch==1.9.0+cu102 in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n",
            "Requirement already satisfied: torchvision==0.10.0+cu102 in /usr/local/lib/python3.7/dist-packages (0.10.0+cu102)\n",
            "Collecting torchaudio===0.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/20/eab40caad8f4b97f5e91a5de8ba5ec29115e08fa4c9a808725490b7b4844/torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0+cu102) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu102) (1.19.5)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu102) (7.1.2)\n",
            "Installing collected packages: torchaudio\n",
            "Successfully installed torchaudio-0.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJYFDjYr87c3"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0lKBcB2hsUI"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EsIkt2omV1n"
      },
      "source": [
        "python中的super(Net, self).__init__()\n",
        " \n",
        "首先找到Net的父类（比如是类NNet），然后把类Net的对象self转换为类NNet的对象，然后“被转换”的类NNet对象调用自己的init函数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWyz1lgyhwfO"
      },
      "source": [
        "class Net(nn.Module):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1,6,5)\n",
        "    self.conv2 = nn.Conv2d(6,16,5)\n",
        "    self.fc1  = nn.Linear(16*5*5,120)\n",
        "    self.fc2  = nn.Linear(120,84)\n",
        "    self.fc3  = nn.Linear(84,10)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = F.max_pool2d(F.relu(self.conv1(x)),(2,2))\n",
        "    x = F.max_pool2d(F.relu(self.conv2(x)),2)\n",
        "    x = x.view(-1,self.num_flat_features(x))\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "  def num_flat_features(self,x):\n",
        "    size = x.size()[1:]\n",
        "    num_features = 1\n",
        "    for s in size:\n",
        "      num_features *=s\n",
        "    return num_features\n",
        "  \n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3K6LCfMtk0AI",
        "outputId": "2242228e-843b-4cbd-ae4d-a32a37f91855"
      },
      "source": [
        "net = Net()\n",
        "print(next)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<built-in function next>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivm-wLjnso5t",
        "outputId": "a0556563-2490-40a9-b314-b7b1e660a2c8"
      },
      "source": [
        "torch.randn(1,1,32,32)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 1.8178,  0.6415, -0.4277,  ..., -0.5380,  0.0741, -0.8095],\n",
              "          [ 0.4341,  0.8842,  0.7778,  ...,  0.6204,  1.2489, -1.1258],\n",
              "          [-0.5250,  1.8733, -0.6832,  ..., -0.2369, -1.2173, -0.3649],\n",
              "          ...,\n",
              "          [-0.7369, -0.9011,  1.3844,  ..., -1.1841,  0.4685, -0.8936],\n",
              "          [ 1.0979,  0.6499,  0.3448,  ..., -1.2502, -0.1374,  0.3688],\n",
              "          [ 0.2469, -0.2894,  1.3907,  ...,  1.0479,  0.8580,  0.0217]]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vV6Zn12gi9Hj",
        "outputId": "6b5f2cfe-54e5-4be5-8f96-e40f468a261b"
      },
      "source": [
        "input = torch.randn(1,1,32,32)\n",
        "out = net(input)\n",
        "print(out)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.0779, -0.0375,  0.1755,  0.0235, -0.0017, -0.0762, -0.0285,  0.0404,\n",
            "         -0.1282,  0.0478]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UwBnW2MtsZ6"
      },
      "source": [
        "清零所有参数的梯度缓存，进行随机梯度的反向传播"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btEwokP3t8nr"
      },
      "source": [
        "net.zero_grad()#清零梯度缓存\n",
        "out.backward(torch.randn(1,10))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8NrpqZLqh4o"
      },
      "source": [
        "**LOSS损失函数**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhinQhjCqfm8"
      },
      "source": [
        "一个损失函数接受一对(output, target)作为输入，计算一个值来估计网络的输出和目标值相差多少\n",
        "nn.MSELoss计算输出和目标的均方误差(mean-squared error)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsIuLv_8qg1w",
        "outputId": "5593539b-930e-444c-9f7d-2ab2427054b5"
      },
      "source": [
        "output = net(input)\n",
        "target = torch.randn(10)\n",
        "target = target.view(1,-1)\n",
        "criterion = nn.MSELoss()\n",
        "loss = criterion(output,target)\n",
        "print(loss)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.3156, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aH_XeymMwYwG",
        "outputId": "17a80746-3603-4a80-e8cc-3ee2ed377752"
      },
      "source": [
        "print(loss.grad_fn)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<MseLossBackward object at 0x7f8b3c6e3150>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgZIQ6C0w4M9"
      },
      "source": [
        "反向传播误差"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xt7iGW08w79W",
        "outputId": "f71ffc76-4397-4bb8-d7a2-4f5e4a0a274d"
      },
      "source": [
        "net.zero_grad()#清除参数的梯度\n",
        "print(\"未反向传播的梯度：\",net.conv1.bias.grad)\n",
        "loss.backward(retain_graph=True)\n",
        "print(\"反向传播之后的梯度：\",net.conv1.bias.grad)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "未反向传播的梯度： tensor([0., 0., 0., 0., 0., 0.])\n",
            "反向传播之后的梯度： tensor([ 0.0033,  0.0142,  0.0035,  0.0095, -0.0212, -0.0204])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQbrR-dmzQIu"
      },
      "source": [
        "**更新权重**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntPiUiPJzWL8"
      },
      "source": [
        "SGD随机梯度下降法\n",
        ">SGD算法效率高，每次随机选择一个mini-batch去计算梯度，在minibatch-loss上的梯度显然是original-loss上的梯度的无偏估计，因此利用minibatch-loss上的梯度可以近似original-loss上的梯度，并且每走一步只需要遍历一个minibatch（一～几百）的数据。<br>\n",
        "<br>\n",
        "> weight = weight - learning_rate * gradient\n",
        "\n",
        "​\t"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sV7WPVxszTVm",
        "outputId": "9d74c248-46d5-464c-d040-37617d1db2ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "learning_rate = 0.01\n",
        "for f in net.parameters():\n",
        "  f.data.sub_(learning_rate * f.grad.data)\n",
        "  print(f.data)\n",
        "#官方给了一种优化\n",
        "#可以使用torch.optim\n",
        "#optimizer = optim.SGD(net.parameters(),learning_rate)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[[ 0.0690, -0.1547,  0.1085,  0.0669, -0.0847],\n",
            "          [ 0.1635, -0.1473,  0.0665, -0.1130,  0.0633],\n",
            "          [-0.0602, -0.1616,  0.0756,  0.1222, -0.1256],\n",
            "          [-0.1570,  0.1239, -0.1683,  0.1423, -0.1586],\n",
            "          [-0.0468, -0.1204, -0.0509, -0.1909,  0.1294]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0424, -0.1151,  0.1043,  0.0119, -0.0924],\n",
            "          [-0.0835, -0.1650, -0.0679,  0.0566, -0.0468],\n",
            "          [-0.0228, -0.0015, -0.0696, -0.0216,  0.0949],\n",
            "          [-0.0945,  0.1118, -0.0824,  0.1842,  0.1202],\n",
            "          [-0.1431, -0.0126,  0.0170, -0.0194, -0.0850]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0490,  0.0690,  0.0914,  0.0444,  0.0178],\n",
            "          [ 0.1851,  0.0240, -0.0002,  0.1503, -0.1970],\n",
            "          [-0.0971, -0.0508,  0.0101,  0.0130, -0.1099],\n",
            "          [-0.1921, -0.0730,  0.0573,  0.0568,  0.0445],\n",
            "          [-0.1939, -0.0385, -0.1551, -0.1298,  0.1839]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0118, -0.0259, -0.1413,  0.0980, -0.1356],\n",
            "          [-0.0561,  0.1614, -0.1885, -0.0025,  0.0007],\n",
            "          [ 0.1833,  0.0905,  0.1919,  0.0102, -0.0519],\n",
            "          [-0.1034, -0.1991,  0.0608, -0.1817,  0.0391],\n",
            "          [ 0.0277, -0.1895, -0.1726, -0.0943, -0.0398]]],\n",
            "\n",
            "\n",
            "        [[[-0.1267,  0.1147, -0.0833,  0.0448,  0.0536],\n",
            "          [ 0.0848, -0.0240, -0.0771, -0.0160, -0.1836],\n",
            "          [ 0.1415, -0.0103,  0.0538, -0.0281, -0.1193],\n",
            "          [-0.1420,  0.1678,  0.0315, -0.0446,  0.0843],\n",
            "          [ 0.1233, -0.1444,  0.0137, -0.1094,  0.1850]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1383,  0.1437, -0.0855,  0.0111,  0.0496],\n",
            "          [ 0.0291, -0.1415,  0.0410, -0.1825,  0.0176],\n",
            "          [-0.0180,  0.0228, -0.0985, -0.1579,  0.1653],\n",
            "          [ 0.1438, -0.1789,  0.1060, -0.1771, -0.0054],\n",
            "          [ 0.0093,  0.0302,  0.1499,  0.0468, -0.0156]]]])\n",
            "tensor([ 0.1397,  0.1978, -0.1266, -0.0085,  0.0168, -0.0529])\n",
            "tensor([[[[ 7.5314e-02,  5.6650e-02,  5.6145e-02, -6.5903e-02,  3.0127e-02],\n",
            "          [ 6.8433e-02, -2.2833e-02,  1.3038e-03, -5.1286e-02,  5.3344e-02],\n",
            "          [ 5.6885e-03,  5.1083e-02,  3.0130e-02, -7.9758e-02, -2.8248e-02],\n",
            "          [-3.5050e-02, -7.4143e-03,  7.6832e-02, -2.3120e-02,  5.7310e-02],\n",
            "          [-7.7160e-02, -3.1848e-02, -6.8820e-02, -1.4659e-02,  2.8827e-02]],\n",
            "\n",
            "         [[-1.5513e-04, -5.4239e-02,  2.5169e-02,  8.0991e-02,  7.9470e-02],\n",
            "          [-2.6381e-02,  2.9045e-02,  3.5040e-02,  2.7578e-02, -5.1461e-02],\n",
            "          [ 7.4930e-02,  4.1050e-02, -3.4805e-02, -4.6178e-02,  2.5444e-02],\n",
            "          [ 1.7420e-02,  4.0141e-02, -3.5256e-02,  7.4168e-02, -7.3241e-02],\n",
            "          [ 1.2740e-02, -7.6307e-02, -2.9942e-02,  6.9623e-02,  3.8493e-02]],\n",
            "\n",
            "         [[-1.5519e-03,  3.9356e-02,  7.2339e-02, -3.2882e-02, -3.1996e-02],\n",
            "          [-2.6973e-02, -6.3244e-02, -4.5854e-02,  7.2525e-02,  5.8082e-02],\n",
            "          [ 1.3190e-02, -1.8537e-02,  2.9083e-02, -7.5662e-02, -4.0202e-02],\n",
            "          [ 3.4510e-02, -3.8415e-03, -5.1214e-02,  4.1776e-03, -3.2402e-02],\n",
            "          [-3.6893e-02, -2.5405e-02,  3.9923e-02, -2.3961e-02,  7.7179e-02]],\n",
            "\n",
            "         [[ 2.9291e-02,  6.0685e-02,  2.4441e-02, -6.5240e-02,  7.5680e-02],\n",
            "          [ 2.5164e-02, -7.0212e-02, -2.4388e-02, -5.4914e-02, -5.2135e-02],\n",
            "          [ 4.6184e-02, -5.4051e-02, -4.7866e-02, -1.8408e-02, -4.1829e-02],\n",
            "          [ 5.8072e-02, -6.2584e-02, -1.5363e-02, -1.5887e-03, -4.1869e-02],\n",
            "          [ 1.9168e-02,  5.9451e-02,  6.1251e-02,  4.3053e-02, -5.6816e-02]],\n",
            "\n",
            "         [[-4.0002e-02,  4.2899e-02,  9.5472e-03, -5.8762e-02,  1.0187e-02],\n",
            "          [-5.4606e-02,  1.3041e-02, -1.0276e-03, -4.5755e-02,  3.6788e-02],\n",
            "          [ 3.0349e-02,  1.4136e-02,  4.3687e-02,  3.7473e-02, -5.9584e-02],\n",
            "          [ 6.5262e-02, -6.4465e-02, -5.7255e-02,  6.5416e-02, -2.4813e-02],\n",
            "          [ 5.0237e-03, -6.8253e-02, -7.2340e-02,  7.8451e-02,  1.8497e-02]],\n",
            "\n",
            "         [[ 4.7889e-02, -6.0623e-02,  5.3858e-02,  4.3272e-02,  1.2900e-02],\n",
            "          [-1.4755e-02, -5.6753e-02, -2.4047e-02,  5.2750e-02,  1.1418e-02],\n",
            "          [-2.8156e-03,  4.7139e-02,  6.6173e-02, -6.5433e-02,  5.9052e-02],\n",
            "          [ 5.0346e-02, -1.4098e-02, -5.7248e-02,  5.6345e-02, -4.8390e-02],\n",
            "          [ 6.5557e-02, -3.8386e-02,  7.5182e-02,  6.2446e-02,  5.1100e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.5670e-02,  7.2634e-02, -6.5026e-02,  4.9570e-02,  6.1614e-02],\n",
            "          [-7.0168e-02,  2.1968e-02, -5.8883e-02,  7.7961e-04, -7.0891e-03],\n",
            "          [ 6.0818e-02, -6.9209e-02,  1.8512e-02,  4.1843e-02, -4.2673e-02],\n",
            "          [ 6.5785e-02,  1.0413e-02, -2.9733e-02, -1.0016e-02, -1.7177e-02],\n",
            "          [ 7.5042e-02,  5.8789e-02, -6.2867e-02,  7.8475e-02, -5.1099e-02]],\n",
            "\n",
            "         [[-1.4689e-02, -2.9026e-03, -6.4353e-02,  7.6745e-02,  6.3296e-02],\n",
            "          [ 7.5501e-02,  1.8094e-03, -7.9350e-02,  4.8885e-02, -7.5551e-02],\n",
            "          [-3.7172e-02, -5.3571e-02, -3.2696e-02,  8.4781e-03, -5.0487e-04],\n",
            "          [ 1.1601e-02,  6.9960e-02,  3.4756e-02,  5.9091e-02,  3.8135e-02],\n",
            "          [ 6.7800e-02,  7.8340e-02,  5.9972e-02,  1.6246e-02, -7.4049e-02]],\n",
            "\n",
            "         [[ 3.6249e-02,  5.2492e-02, -5.1514e-02,  5.4463e-02,  3.4840e-02],\n",
            "          [ 3.6028e-02, -7.1708e-02,  6.8177e-02,  2.5191e-02,  6.7633e-03],\n",
            "          [ 6.9664e-02,  5.7387e-02,  7.3419e-02,  6.8613e-02, -8.1358e-02],\n",
            "          [ 3.2405e-02,  3.0712e-02,  5.1746e-02,  1.9252e-02,  2.2352e-02],\n",
            "          [ 7.4776e-02, -2.8252e-02,  3.7630e-02, -6.9513e-02,  3.3276e-02]],\n",
            "\n",
            "         [[-1.6892e-02, -3.4488e-02,  2.7316e-03,  5.4106e-02, -3.7013e-02],\n",
            "          [ 4.4478e-02, -1.3961e-02,  5.7119e-02,  7.8655e-03, -7.0602e-02],\n",
            "          [ 4.9377e-03,  2.3544e-02, -1.2745e-02,  2.8037e-02, -5.1547e-02],\n",
            "          [ 7.1059e-02,  3.9921e-02,  4.6791e-02, -3.0952e-02,  5.6385e-02],\n",
            "          [-3.5699e-02, -6.7802e-02,  6.5829e-02, -2.5489e-02, -5.9599e-02]],\n",
            "\n",
            "         [[ 1.1795e-02,  6.1615e-02, -8.1410e-02,  4.8413e-02,  6.9058e-02],\n",
            "          [ 6.3220e-02,  6.7499e-02,  3.4510e-02,  6.9206e-02, -7.9476e-02],\n",
            "          [-2.1550e-02, -7.3868e-02,  3.0217e-03, -8.7529e-03, -5.6145e-02],\n",
            "          [ 3.0927e-02, -8.0529e-02,  3.9732e-02, -5.8957e-02,  3.0973e-02],\n",
            "          [ 4.4178e-02, -5.6890e-02, -7.1458e-02, -6.2708e-02, -5.7749e-02]],\n",
            "\n",
            "         [[-1.0949e-02,  4.7534e-02,  7.9236e-02,  4.6772e-02,  6.1017e-02],\n",
            "          [-3.0865e-02,  7.2893e-02, -3.7196e-02,  7.1994e-02, -6.3303e-02],\n",
            "          [-3.2312e-02,  2.6687e-03,  1.5073e-02, -2.9161e-02,  3.7750e-02],\n",
            "          [-4.4600e-02,  7.1589e-02, -7.4347e-02,  1.2224e-02,  2.0581e-02],\n",
            "          [ 2.9190e-02, -5.1909e-02,  1.8628e-02,  6.6714e-02,  6.4239e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.4573e-02, -3.1405e-02, -2.3725e-02,  8.0863e-02, -2.1717e-02],\n",
            "          [-1.1236e-02,  5.4214e-02, -4.0403e-02,  7.8073e-02,  6.7755e-02],\n",
            "          [ 1.8836e-02,  5.6314e-02,  3.6663e-02, -3.7781e-02,  5.7440e-02],\n",
            "          [-2.8967e-02,  6.7721e-02,  6.1166e-02, -5.0314e-02,  5.5558e-02],\n",
            "          [ 7.2728e-02, -6.1665e-02, -3.2437e-03, -7.1368e-02, -6.4258e-02]],\n",
            "\n",
            "         [[-7.4240e-03,  3.3854e-02,  8.0170e-02,  6.4582e-02,  1.6950e-02],\n",
            "          [ 9.8105e-03,  5.8601e-02,  5.6817e-02, -1.0936e-02, -7.2171e-02],\n",
            "          [ 7.3761e-03, -2.5153e-02, -5.2077e-02,  4.7222e-02, -2.0327e-02],\n",
            "          [-2.2701e-02,  1.8060e-04, -1.8819e-02,  1.2030e-02, -4.3840e-02],\n",
            "          [ 5.4393e-02,  2.3627e-02,  6.8703e-02,  3.9147e-02,  5.1139e-02]],\n",
            "\n",
            "         [[-2.4121e-03, -2.1846e-02, -2.5964e-02,  1.9979e-02, -9.4057e-05],\n",
            "          [ 4.8668e-02, -3.1473e-02, -4.8045e-02,  5.5571e-02,  7.9550e-02],\n",
            "          [ 8.1023e-02, -6.8010e-02, -7.3130e-02,  3.3984e-02, -5.9384e-02],\n",
            "          [ 7.5560e-02,  5.1743e-02,  1.6547e-02,  2.8206e-02, -4.7595e-02],\n",
            "          [-2.9076e-02,  6.8255e-02,  8.0642e-02, -7.8765e-02, -1.2302e-02]],\n",
            "\n",
            "         [[-8.0861e-02, -3.8119e-03, -7.0342e-02, -7.7209e-04, -5.7801e-02],\n",
            "          [ 6.0023e-03,  7.1960e-02, -5.8367e-02, -3.7971e-02, -4.7680e-02],\n",
            "          [-2.5556e-02, -1.5456e-02,  1.2543e-02,  3.9731e-02,  2.1029e-02],\n",
            "          [ 7.6787e-02,  8.7688e-03, -4.2730e-02,  1.0783e-02,  3.7986e-02],\n",
            "          [ 5.5937e-02, -5.9050e-02, -4.3732e-02,  3.7515e-02,  7.2015e-03]],\n",
            "\n",
            "         [[-3.9446e-02, -4.3857e-02,  6.6619e-02,  2.1108e-02,  5.0350e-02],\n",
            "          [-2.3980e-02,  3.9366e-02,  1.2573e-02,  4.3498e-02,  1.8793e-02],\n",
            "          [ 1.6494e-03, -7.7133e-02, -9.8120e-03,  6.9745e-02, -3.7292e-02],\n",
            "          [ 4.6852e-02, -2.0308e-02, -1.8855e-02,  6.3724e-02,  8.1524e-02],\n",
            "          [-6.8641e-02,  7.0149e-02,  2.4677e-02, -2.0392e-02, -6.8611e-02]],\n",
            "\n",
            "         [[-7.0159e-02, -1.3520e-02,  7.7490e-02,  1.0936e-02, -7.3772e-02],\n",
            "          [-1.2878e-02, -5.5463e-04,  3.9778e-03,  1.5905e-02, -4.2585e-02],\n",
            "          [ 2.1824e-02,  3.7144e-02,  9.5857e-04,  4.6722e-02, -2.6996e-03],\n",
            "          [ 3.3735e-02,  2.0386e-02, -2.0069e-02, -5.1159e-02, -7.3170e-02],\n",
            "          [-1.2452e-02, -6.8213e-02,  5.3785e-02,  3.0181e-02, -3.8835e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-4.6805e-02, -1.3433e-02, -5.4135e-02,  5.7392e-02,  5.0757e-02],\n",
            "          [-3.7798e-02, -2.4037e-02,  1.6267e-02, -5.9324e-02, -2.8312e-02],\n",
            "          [-2.9868e-02, -6.8465e-02,  5.8280e-02,  3.0191e-02, -2.8406e-02],\n",
            "          [ 1.9262e-02, -1.1496e-04, -6.8596e-02,  7.7240e-02, -4.4752e-02],\n",
            "          [ 9.3134e-03, -4.5032e-02,  4.9209e-02,  2.8669e-03,  5.9381e-03]],\n",
            "\n",
            "         [[ 3.2379e-02, -5.1485e-02, -7.0728e-02,  6.9045e-02, -3.3590e-02],\n",
            "          [ 5.0360e-02,  2.5081e-02,  3.2187e-02, -5.1665e-02,  3.1204e-02],\n",
            "          [-1.2657e-02, -2.3314e-02,  2.9696e-02, -1.5396e-02, -4.4005e-03],\n",
            "          [-3.5564e-02,  3.4135e-02, -4.9304e-02,  4.4031e-02, -7.5438e-02],\n",
            "          [ 2.4584e-02,  5.7638e-02, -5.5572e-02, -9.3482e-03, -1.9151e-02]],\n",
            "\n",
            "         [[ 7.4749e-02,  8.0411e-02, -6.7329e-02,  3.7517e-02, -6.3603e-02],\n",
            "          [-1.6890e-02,  3.9958e-02,  6.0172e-02,  7.4888e-04, -5.6175e-02],\n",
            "          [ 3.8697e-02,  2.7163e-02,  2.1716e-02,  1.1314e-02,  7.6486e-02],\n",
            "          [-6.9782e-03, -3.8363e-02, -2.9577e-02,  8.0750e-04, -2.4014e-02],\n",
            "          [-1.8693e-02, -6.5115e-02,  8.1425e-02,  2.4868e-02,  7.4481e-02]],\n",
            "\n",
            "         [[-3.1849e-02, -6.4361e-02, -5.3551e-02,  3.7857e-02,  3.5879e-03],\n",
            "          [ 1.4723e-02,  3.3283e-02,  3.3324e-02, -7.1303e-02,  6.7693e-02],\n",
            "          [ 1.1242e-02, -2.3842e-02, -7.2865e-02, -6.6569e-02, -5.6648e-02],\n",
            "          [ 3.4778e-02, -2.8059e-02, -2.2737e-02, -6.5142e-02,  4.9317e-02],\n",
            "          [ 3.6151e-02, -3.1534e-02,  3.4590e-02,  4.4924e-02, -1.5219e-03]],\n",
            "\n",
            "         [[ 1.5262e-02, -6.2998e-02, -7.9278e-02, -2.4045e-03,  2.9325e-02],\n",
            "          [ 5.1504e-02,  3.3135e-02,  1.4245e-02,  1.7978e-02, -6.5215e-02],\n",
            "          [-7.4971e-04,  6.1249e-02,  3.2403e-02, -1.0835e-02, -6.0391e-02],\n",
            "          [-5.1701e-02, -2.3671e-02, -1.6862e-02, -7.2155e-02, -2.8345e-02],\n",
            "          [ 5.0903e-02,  3.6083e-02, -7.3350e-03, -4.7600e-02, -1.6962e-02]],\n",
            "\n",
            "         [[-5.3431e-03, -3.6366e-02,  2.8905e-02,  7.0189e-02, -8.2410e-03],\n",
            "          [ 7.7028e-02,  7.6387e-02,  1.8684e-02, -1.1524e-02, -1.2023e-02],\n",
            "          [-1.6833e-02, -3.4934e-03,  2.9123e-02,  1.5784e-02, -1.8166e-03],\n",
            "          [-3.0547e-02,  5.3541e-03,  2.7038e-02, -7.9136e-03, -8.0486e-02],\n",
            "          [ 7.3629e-02,  5.3631e-02,  7.4113e-02,  6.7723e-02,  5.7190e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 6.8797e-02,  2.4542e-02, -8.0864e-02, -3.5056e-03, -6.3230e-02],\n",
            "          [-1.1131e-02, -5.5229e-02,  8.0659e-02,  7.8758e-02,  1.9354e-02],\n",
            "          [ 3.5200e-02,  7.6752e-02,  3.7351e-02,  4.6989e-02, -1.8342e-02],\n",
            "          [ 6.0774e-02, -6.2280e-02,  8.0818e-02, -7.3236e-02, -6.1522e-02],\n",
            "          [ 2.7403e-02,  6.5123e-02,  3.9861e-02,  4.0954e-02,  7.2137e-02]],\n",
            "\n",
            "         [[-5.4915e-02,  1.2020e-02,  8.0163e-02,  8.3828e-03,  1.9386e-02],\n",
            "          [-2.3422e-02, -4.6617e-02,  1.5261e-02, -3.6794e-02,  1.2059e-02],\n",
            "          [-7.2246e-02, -3.0435e-02,  2.2985e-02,  4.5658e-02,  3.6081e-02],\n",
            "          [-1.0552e-02, -2.8957e-02,  3.9176e-02, -1.4248e-03, -4.5849e-02],\n",
            "          [-4.0811e-02, -6.0858e-02,  2.8459e-02,  5.0392e-02, -7.8510e-02]],\n",
            "\n",
            "         [[ 5.1257e-02, -4.6177e-02, -3.0427e-02, -6.0113e-02, -7.9624e-02],\n",
            "          [-6.9972e-02,  2.5938e-02,  1.9727e-02, -2.7797e-02,  6.7405e-02],\n",
            "          [ 5.7334e-02, -7.1014e-02, -3.2245e-03, -3.9454e-02, -2.2441e-02],\n",
            "          [-6.0725e-02, -3.4464e-02,  2.5177e-02,  3.0173e-02, -3.9464e-02],\n",
            "          [-3.6102e-02,  6.9523e-02, -4.3327e-02, -4.6240e-04, -5.1502e-02]],\n",
            "\n",
            "         [[-6.8215e-02,  6.7536e-02, -7.0679e-02, -6.3179e-02, -2.1210e-02],\n",
            "          [ 7.8082e-02,  2.2684e-02,  2.0219e-02, -7.2290e-03, -2.3746e-02],\n",
            "          [-1.7949e-02, -7.5060e-02, -3.8254e-02,  8.9340e-03,  4.0031e-02],\n",
            "          [-3.7336e-02, -4.9345e-02, -7.5883e-02, -1.1835e-02,  4.1458e-02],\n",
            "          [-7.3424e-03,  7.0580e-02, -3.5440e-02, -7.3666e-02,  6.9777e-02]],\n",
            "\n",
            "         [[-6.9130e-02,  4.5820e-03, -5.7091e-02,  8.2929e-03,  5.0513e-02],\n",
            "          [ 5.1786e-02,  1.5013e-02, -6.1104e-02,  4.5595e-02, -4.4666e-03],\n",
            "          [-1.7212e-02,  5.5735e-02,  2.6231e-02,  1.1244e-02, -4.9761e-02],\n",
            "          [ 4.9310e-02, -7.2415e-02, -3.5880e-02,  6.2525e-03,  7.9838e-03],\n",
            "          [ 7.2386e-02, -7.9399e-02,  4.0322e-02, -2.3540e-02,  6.0810e-02]],\n",
            "\n",
            "         [[-7.8897e-02,  2.8636e-02, -7.3551e-02, -3.5166e-02,  3.4972e-02],\n",
            "          [-7.0054e-03,  2.5633e-02, -7.4228e-02,  3.4747e-02, -6.9865e-02],\n",
            "          [-2.6242e-02,  8.7588e-03, -7.5336e-02, -2.7909e-02,  4.8065e-02],\n",
            "          [-7.8986e-02, -6.2292e-02, -6.9892e-02, -2.8450e-02,  6.2953e-02],\n",
            "          [ 8.0658e-02,  5.9904e-02, -6.7012e-02, -1.6558e-02,  2.9826e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.0186e-02,  2.6397e-02,  2.2323e-02, -3.4980e-02,  8.0863e-02],\n",
            "          [-4.8349e-02, -8.8180e-03, -7.8874e-02,  7.6219e-02, -6.3018e-02],\n",
            "          [ 6.4771e-02,  4.4595e-02,  2.1674e-02, -2.7176e-02, -7.8237e-03],\n",
            "          [ 1.7436e-02,  7.0907e-02, -5.1683e-02, -6.2794e-02,  3.9119e-02],\n",
            "          [-3.9636e-02,  6.2184e-02,  5.8491e-02, -7.3040e-02, -5.4748e-02]],\n",
            "\n",
            "         [[ 2.0422e-02, -6.1989e-02,  6.1282e-02,  3.4109e-02,  1.3810e-02],\n",
            "          [ 4.7845e-02, -9.2032e-03, -1.2030e-02,  2.5104e-02,  8.0436e-02],\n",
            "          [ 7.8230e-02,  7.0476e-02,  1.3833e-02,  4.6686e-03, -2.4502e-02],\n",
            "          [ 6.7798e-03,  6.9396e-03, -4.2650e-02, -1.2933e-02,  4.0266e-02],\n",
            "          [ 4.8074e-02,  4.6249e-02, -7.0223e-02, -1.3350e-02, -4.1155e-02]],\n",
            "\n",
            "         [[-4.9627e-02,  1.9830e-02,  4.8065e-02, -6.5706e-02, -7.1528e-02],\n",
            "          [-3.2225e-02, -4.3387e-02, -7.7062e-02,  4.4929e-02,  5.1320e-02],\n",
            "          [ 3.2623e-02,  4.5132e-02, -4.0031e-02,  8.1052e-02,  4.4072e-02],\n",
            "          [ 6.1622e-02,  3.6123e-02, -3.8540e-02,  6.5523e-02,  6.9260e-03],\n",
            "          [-3.6311e-03,  6.2922e-02, -4.2107e-02,  4.5491e-02, -6.5496e-02]],\n",
            "\n",
            "         [[-6.9535e-02,  7.6885e-02,  1.7805e-02,  6.2234e-02, -4.0812e-02],\n",
            "          [-6.5607e-02, -5.9158e-02, -2.1993e-02, -4.4567e-02,  7.6196e-02],\n",
            "          [ 7.8117e-02, -4.6727e-02, -6.9095e-02,  7.2408e-02,  6.7937e-02],\n",
            "          [-2.4155e-02, -7.6157e-02,  1.2961e-02, -7.5507e-03, -2.9260e-02],\n",
            "          [-8.4330e-03, -6.3555e-02,  8.9657e-04,  1.6504e-02, -3.1900e-02]],\n",
            "\n",
            "         [[-5.2596e-02, -4.5179e-02, -1.3799e-02, -6.4011e-02,  4.7871e-02],\n",
            "          [ 1.0999e-02, -3.2039e-02,  6.8778e-02, -5.1507e-02, -4.5246e-02],\n",
            "          [-3.0699e-02,  2.5235e-02,  1.6571e-02, -3.0212e-02, -7.8382e-02],\n",
            "          [-3.7762e-03,  5.6626e-02,  1.3530e-02, -6.0313e-02, -3.5902e-02],\n",
            "          [ 5.7209e-02, -5.5328e-02, -1.8832e-02, -7.4743e-02, -6.5455e-02]],\n",
            "\n",
            "         [[ 6.8832e-02,  7.4969e-02,  5.7031e-02, -7.7353e-02,  2.7049e-02],\n",
            "          [ 4.7159e-02,  5.5890e-02, -2.4651e-02,  9.6898e-03,  3.4283e-03],\n",
            "          [ 3.3826e-02,  2.5536e-02, -2.1852e-02,  1.7896e-02,  1.4271e-02],\n",
            "          [-6.9581e-02, -5.9656e-02, -2.3421e-02,  8.0163e-02,  1.8562e-02],\n",
            "          [ 5.1655e-03, -2.9062e-02,  1.8693e-02, -4.8833e-03, -4.5128e-02]]]])\n",
            "tensor([ 0.0404, -0.0244, -0.0346,  0.0757,  0.0556,  0.0707,  0.0486,  0.0783,\n",
            "        -0.0572,  0.0595, -0.0413, -0.0800,  0.0516, -0.0124, -0.0802,  0.0280])\n",
            "tensor([[-0.0122,  0.0227, -0.0020,  ...,  0.0412,  0.0067, -0.0015],\n",
            "        [-0.0248,  0.0438,  0.0165,  ..., -0.0092, -0.0006,  0.0048],\n",
            "        [ 0.0370, -0.0390, -0.0074,  ..., -0.0487, -0.0131,  0.0162],\n",
            "        ...,\n",
            "        [-0.0414,  0.0147, -0.0200,  ..., -0.0400, -0.0441, -0.0330],\n",
            "        [-0.0298, -0.0042, -0.0241,  ..., -0.0250,  0.0386,  0.0219],\n",
            "        [ 0.0092, -0.0277, -0.0333,  ..., -0.0487, -0.0197, -0.0198]])\n",
            "tensor([ 1.1989e-02, -3.9031e-03, -4.7649e-02, -8.6047e-04,  4.0736e-02,\n",
            "         3.4499e-02,  8.2829e-03,  3.3484e-02, -4.9287e-02,  3.5885e-02,\n",
            "        -4.5274e-02,  4.3005e-02, -1.5860e-02, -1.7355e-02,  3.4389e-02,\n",
            "        -2.7648e-02, -5.6079e-03,  3.9415e-02,  2.4481e-03, -1.9647e-02,\n",
            "         1.9270e-02,  1.3991e-02, -4.7563e-03, -4.3656e-02, -2.5470e-02,\n",
            "        -7.4750e-03, -4.4660e-02, -3.9208e-02,  4.0538e-02,  3.0405e-02,\n",
            "         2.9789e-02, -3.5325e-02,  2.7675e-02,  3.1860e-02,  3.3557e-02,\n",
            "         1.4724e-02,  1.0216e-02,  3.6104e-02,  4.3327e-02, -4.1843e-02,\n",
            "         2.7443e-03,  2.9705e-02,  2.0252e-02,  3.3853e-02,  9.4065e-03,\n",
            "        -3.1858e-02, -1.9921e-02, -3.5995e-02, -9.9724e-04,  5.4814e-03,\n",
            "        -1.0880e-02,  1.1019e-02, -3.8222e-02,  2.2319e-02,  4.7236e-02,\n",
            "         1.7125e-03, -2.6018e-02,  4.7028e-02,  2.2668e-02, -2.5467e-02,\n",
            "        -1.3328e-02,  3.5230e-02, -2.5851e-02, -1.4618e-02,  9.0297e-03,\n",
            "         2.0681e-02, -3.9617e-02,  1.4423e-02,  4.7975e-02, -4.3964e-05,\n",
            "         1.4000e-02,  2.0995e-02, -1.8423e-02,  4.3211e-02,  3.4433e-02,\n",
            "         4.5707e-02, -2.7007e-04, -1.3950e-02, -3.1983e-02, -8.2868e-05,\n",
            "         6.2218e-03, -5.0256e-02, -2.6126e-02, -1.5071e-02,  2.9886e-03,\n",
            "        -3.6299e-02, -4.5928e-02, -2.8060e-02,  3.3433e-02,  4.2337e-02,\n",
            "         6.8050e-03, -2.7274e-02,  3.0883e-02,  3.5801e-02, -2.8476e-02,\n",
            "         3.9642e-02, -2.8050e-02,  4.0161e-02, -4.1086e-02, -2.1729e-02,\n",
            "        -3.1548e-02,  1.5835e-02, -1.3189e-03,  3.9317e-02,  1.2068e-02,\n",
            "        -1.0553e-02, -1.8340e-02,  3.5093e-02, -6.5130e-03, -2.5523e-03,\n",
            "        -1.5832e-02,  3.1382e-02,  4.9000e-02,  3.6998e-02,  5.8290e-03,\n",
            "         1.4011e-03, -4.0563e-02, -1.7103e-02,  1.9184e-02, -4.8411e-02])\n",
            "tensor([[-0.0341,  0.0502,  0.0435,  ..., -0.0847, -0.0361, -0.0294],\n",
            "        [ 0.0079, -0.0284,  0.0082,  ..., -0.0695, -0.0338,  0.0168],\n",
            "        [-0.0865, -0.0280,  0.0664,  ..., -0.0724, -0.0632,  0.0336],\n",
            "        ...,\n",
            "        [ 0.0111, -0.0306, -0.0159,  ..., -0.0096, -0.0612,  0.0420],\n",
            "        [-0.0011,  0.0105,  0.0528,  ...,  0.0528, -0.0879,  0.0686],\n",
            "        [-0.0291, -0.0018,  0.0709,  ...,  0.0351,  0.0822,  0.0782]])\n",
            "tensor([-0.0746,  0.0905, -0.0736,  0.0679, -0.0195,  0.0855,  0.0722, -0.0786,\n",
            "         0.0677, -0.0306, -0.0400,  0.0557,  0.0396,  0.0874,  0.0528,  0.0610,\n",
            "        -0.0129, -0.0411,  0.0384, -0.0249,  0.0007, -0.0054, -0.0197, -0.0688,\n",
            "        -0.0663, -0.0540,  0.0332, -0.0765, -0.0383, -0.0862,  0.0422,  0.0863,\n",
            "        -0.0563,  0.0351,  0.0253, -0.0754,  0.0108,  0.0511, -0.0059, -0.0200,\n",
            "        -0.0355,  0.0766,  0.0727, -0.0170, -0.0786,  0.0331, -0.0837,  0.0367,\n",
            "         0.0736,  0.0026, -0.0027, -0.0286,  0.0641,  0.0363, -0.0069, -0.0070,\n",
            "        -0.0796,  0.0097, -0.0868, -0.0586, -0.0613, -0.0217, -0.0861,  0.0243,\n",
            "         0.0041, -0.0530, -0.0406, -0.0560,  0.0387, -0.0117,  0.0125,  0.0521,\n",
            "        -0.0049,  0.0422, -0.0809,  0.0682, -0.0866,  0.0801, -0.0110,  0.0526,\n",
            "        -0.0745,  0.0167,  0.0827,  0.0364])\n",
            "tensor([[ 0.0020,  0.0831,  0.0984, -0.1037, -0.0701,  0.1011, -0.0198,  0.1047,\n",
            "          0.0702,  0.0740,  0.0305, -0.0708, -0.0663, -0.0778, -0.0550, -0.1036,\n",
            "          0.0532, -0.0097, -0.0806,  0.0291,  0.0336,  0.0566, -0.1012,  0.0153,\n",
            "         -0.0318,  0.0652, -0.0815,  0.0231, -0.1004,  0.0865,  0.0430, -0.0458,\n",
            "          0.0239,  0.0519, -0.0828,  0.1062, -0.0797,  0.1041,  0.0910,  0.0217,\n",
            "         -0.0405, -0.0564,  0.0741,  0.0533, -0.0970,  0.0157,  0.0663,  0.0312,\n",
            "          0.0622, -0.0713, -0.0069, -0.0762,  0.1069, -0.0014,  0.0269, -0.0157,\n",
            "         -0.0879,  0.0172, -0.0168, -0.0423, -0.1022,  0.1049, -0.0729, -0.1063,\n",
            "          0.0201, -0.0493,  0.0799,  0.0344, -0.1031,  0.0857, -0.0644, -0.0687,\n",
            "         -0.0588, -0.0114,  0.0858, -0.0058,  0.0231,  0.0170, -0.0002, -0.0502,\n",
            "         -0.0670,  0.0925,  0.0167, -0.1056],\n",
            "        [ 0.0540,  0.0678, -0.0964,  0.0273, -0.1070,  0.0561, -0.0446, -0.0220,\n",
            "         -0.0497, -0.0249, -0.0986, -0.0611,  0.0935, -0.0320, -0.0570, -0.0663,\n",
            "         -0.0216,  0.0127, -0.0104,  0.1029, -0.1057, -0.1009, -0.0563, -0.0436,\n",
            "         -0.0464,  0.0775, -0.0474, -0.0596,  0.0691, -0.0617, -0.0259,  0.0631,\n",
            "          0.1042,  0.0380,  0.0730, -0.0699, -0.0712, -0.0868,  0.0632,  0.0538,\n",
            "         -0.0357,  0.0792, -0.0886, -0.0215,  0.0219,  0.1042,  0.0112, -0.0596,\n",
            "          0.0863,  0.0576,  0.0945,  0.0914, -0.0995,  0.0367, -0.0098, -0.0590,\n",
            "         -0.0471, -0.0864,  0.0751,  0.0118, -0.0748, -0.0793,  0.0905, -0.0416,\n",
            "         -0.0182, -0.1050, -0.0585,  0.0786, -0.0660,  0.0362, -0.0663,  0.0305,\n",
            "         -0.0995, -0.0141, -0.0794,  0.0991, -0.0123,  0.0705, -0.0961, -0.0737,\n",
            "          0.0258,  0.0132,  0.1008,  0.1016],\n",
            "        [-0.0100,  0.0214, -0.0237,  0.0020, -0.1037, -0.0045,  0.0291,  0.1080,\n",
            "         -0.0639,  0.0945,  0.0325,  0.0513,  0.0540, -0.0783,  0.0198,  0.0957,\n",
            "          0.0223, -0.0110,  0.0290,  0.0521,  0.0976,  0.0070, -0.1085, -0.0261,\n",
            "         -0.0185,  0.0225, -0.0534, -0.0685,  0.0303,  0.0112, -0.0253,  0.0357,\n",
            "          0.0713, -0.0280, -0.1021, -0.0358,  0.0818,  0.0611, -0.0513,  0.0969,\n",
            "          0.0918, -0.0891, -0.1029, -0.0337, -0.0160,  0.0903, -0.0113, -0.0655,\n",
            "         -0.0813,  0.0022, -0.0128, -0.0112, -0.0044,  0.0723,  0.0419, -0.0221,\n",
            "          0.0711, -0.0380,  0.0715,  0.0393,  0.0548, -0.0269,  0.0563, -0.0397,\n",
            "         -0.1091,  0.0592, -0.0252, -0.0803, -0.0470, -0.0360,  0.0309,  0.0171,\n",
            "          0.0405,  0.0136, -0.0298,  0.0012, -0.0725,  0.0574,  0.1039, -0.0420,\n",
            "          0.0601, -0.0148,  0.0530, -0.0056],\n",
            "        [-0.0913,  0.0579, -0.0059, -0.0268, -0.0795,  0.0251,  0.0688,  0.0607,\n",
            "          0.0039,  0.0956, -0.0267,  0.0378,  0.0096, -0.0568, -0.0612, -0.0793,\n",
            "         -0.0225,  0.0017,  0.0144, -0.0267, -0.0978,  0.0524,  0.0825, -0.0472,\n",
            "          0.0705,  0.0085, -0.0796, -0.0615,  0.0735, -0.0033, -0.1081,  0.0123,\n",
            "         -0.0479,  0.0796, -0.0067,  0.0978,  0.0037,  0.0905, -0.0436,  0.0713,\n",
            "          0.1085,  0.0770, -0.0680,  0.0006,  0.0307, -0.0595, -0.1031, -0.0805,\n",
            "         -0.0719,  0.0849, -0.0414,  0.0854, -0.0647,  0.0810,  0.0143, -0.0022,\n",
            "          0.0063, -0.0884,  0.0093,  0.0398,  0.0665, -0.1003, -0.0763, -0.0863,\n",
            "          0.0656,  0.0691,  0.1083,  0.0455,  0.0388, -0.0872,  0.0227, -0.0649,\n",
            "          0.0773, -0.0219,  0.0820,  0.0446,  0.1020, -0.0258, -0.0258, -0.0380,\n",
            "         -0.0499, -0.0612, -0.0275, -0.0125],\n",
            "        [ 0.0381,  0.0250, -0.0898, -0.0814, -0.0630,  0.0922, -0.0980,  0.0062,\n",
            "          0.0785, -0.0986,  0.0488,  0.0386,  0.0343,  0.0992, -0.0175,  0.0970,\n",
            "          0.0968, -0.0483,  0.0467,  0.0783, -0.0370,  0.0873, -0.0919,  0.0379,\n",
            "          0.0510, -0.0727, -0.0556, -0.0878,  0.0521, -0.0078,  0.0189, -0.0966,\n",
            "         -0.0980, -0.0844, -0.0780,  0.0707,  0.0316,  0.0098, -0.0771,  0.0160,\n",
            "          0.0931, -0.0785, -0.0367, -0.0866, -0.0573,  0.0881,  0.0926, -0.0287,\n",
            "         -0.0704, -0.0938, -0.0460,  0.0708, -0.0963,  0.0552,  0.0380,  0.0274,\n",
            "         -0.0054,  0.1087, -0.0216, -0.0306, -0.1050,  0.0025,  0.0824, -0.0915,\n",
            "          0.0494,  0.0390,  0.0802,  0.0999, -0.0772,  0.0611, -0.0402, -0.0457,\n",
            "          0.0775,  0.0888,  0.0319,  0.1004, -0.1074,  0.0778, -0.0856, -0.0998,\n",
            "          0.0442, -0.0012,  0.0552,  0.1081],\n",
            "        [-0.0985,  0.0676, -0.0085,  0.0749, -0.1008, -0.0401,  0.0850,  0.1087,\n",
            "         -0.0749,  0.0321, -0.0100,  0.0538, -0.0406, -0.0465, -0.0531,  0.0288,\n",
            "         -0.0647,  0.0023, -0.1052, -0.1013, -0.0064,  0.0663,  0.0478,  0.0252,\n",
            "          0.0934, -0.0524,  0.0506,  0.0444, -0.0636,  0.0233, -0.0905,  0.0675,\n",
            "         -0.0539, -0.1063, -0.0858,  0.0963,  0.0878, -0.0466, -0.0820, -0.1062,\n",
            "          0.0653, -0.0066, -0.0368, -0.0741, -0.0851,  0.1046, -0.0991,  0.0718,\n",
            "          0.0092,  0.0179,  0.0803, -0.0238,  0.0024,  0.0090,  0.0349,  0.0618,\n",
            "         -0.0942,  0.0799,  0.0681, -0.1003,  0.0221, -0.0767, -0.0959,  0.0968,\n",
            "         -0.0376, -0.0793,  0.0016,  0.0531,  0.0358, -0.0661, -0.0780,  0.0224,\n",
            "         -0.0767, -0.0689, -0.0946,  0.0908,  0.0819, -0.0251,  0.0597,  0.0944,\n",
            "          0.0470, -0.0001, -0.0971,  0.0706],\n",
            "        [-0.0196,  0.0993,  0.0264, -0.0294,  0.0508, -0.0576,  0.0465, -0.0323,\n",
            "          0.0417,  0.0159, -0.0922, -0.0767, -0.0176,  0.0451, -0.0568, -0.0466,\n",
            "          0.1053, -0.1005,  0.0526, -0.0517,  0.0307, -0.0353, -0.0446,  0.0418,\n",
            "         -0.0171,  0.0557,  0.0223, -0.0768, -0.0741,  0.0203,  0.0438, -0.0393,\n",
            "          0.0825,  0.0198,  0.0688, -0.0774,  0.0419, -0.0401,  0.0993, -0.0033,\n",
            "          0.0719, -0.1082,  0.0750,  0.1004, -0.0297, -0.0736, -0.1067, -0.0151,\n",
            "          0.0485,  0.0149,  0.0409, -0.0685,  0.0723, -0.0269,  0.0923,  0.0211,\n",
            "         -0.0052,  0.0655,  0.0416,  0.0641, -0.0066, -0.0140,  0.0072, -0.0084,\n",
            "         -0.0308, -0.1010,  0.0526, -0.0899,  0.1050,  0.0949, -0.1054, -0.1071,\n",
            "         -0.0754,  0.0019,  0.0320,  0.0383, -0.0997,  0.0455,  0.0878, -0.0931,\n",
            "         -0.0342, -0.0124,  0.0457, -0.0913],\n",
            "        [-0.0372,  0.0575,  0.0367,  0.0723,  0.0508, -0.0496, -0.0445, -0.1048,\n",
            "         -0.0330,  0.0650,  0.1011,  0.0899, -0.0689, -0.1008, -0.0786,  0.0633,\n",
            "         -0.0457,  0.0030,  0.0443, -0.1019, -0.0891, -0.0346,  0.0656, -0.0667,\n",
            "         -0.0616, -0.0877, -0.0020, -0.0519, -0.0221,  0.0463, -0.0422,  0.0319,\n",
            "         -0.0741, -0.0491, -0.0682, -0.0676,  0.0639,  0.0396,  0.0789,  0.0619,\n",
            "         -0.1047,  0.0113,  0.0065, -0.0846,  0.0225, -0.0580, -0.0039,  0.0883,\n",
            "          0.0408, -0.0687,  0.0112,  0.0040,  0.0707,  0.0639, -0.0249, -0.0295,\n",
            "          0.0041, -0.0586,  0.0153, -0.0842,  0.0257,  0.0929, -0.0477,  0.0941,\n",
            "         -0.0856,  0.0843, -0.0121,  0.0988,  0.0801, -0.0102, -0.0851, -0.0208,\n",
            "         -0.0585, -0.0850,  0.0307,  0.1086,  0.0736, -0.0942, -0.0414,  0.0272,\n",
            "         -0.1056,  0.0242, -0.0575, -0.1029],\n",
            "        [-0.1003, -0.0863,  0.0314,  0.0347, -0.0501, -0.0444,  0.0891, -0.0084,\n",
            "         -0.0869,  0.0091,  0.0132, -0.0272, -0.1037,  0.0311, -0.0904,  0.0869,\n",
            "         -0.0275,  0.0382, -0.0719, -0.0152, -0.0422,  0.0669, -0.0436,  0.0734,\n",
            "          0.0297,  0.0848, -0.0748, -0.0952, -0.0572,  0.0312, -0.0553, -0.0212,\n",
            "          0.0408,  0.0379,  0.0044, -0.0402, -0.0987,  0.0639, -0.0682, -0.0242,\n",
            "          0.0860, -0.0871,  0.1067, -0.0642,  0.1010,  0.0493, -0.0275, -0.0995,\n",
            "          0.0626,  0.0565, -0.0719,  0.0301, -0.0097, -0.1053,  0.0112, -0.0010,\n",
            "         -0.0966,  0.0641,  0.0267,  0.1072, -0.0512, -0.0761, -0.1076, -0.0942,\n",
            "         -0.0969,  0.0993, -0.0366, -0.0094,  0.0189,  0.0148, -0.0363,  0.0691,\n",
            "          0.0761, -0.0873, -0.0738, -0.0192, -0.0523, -0.0500,  0.0477, -0.0256,\n",
            "          0.1016, -0.0865,  0.0394,  0.0088],\n",
            "        [-0.0019, -0.0935, -0.0226,  0.0750,  0.0197, -0.0588,  0.0548, -0.0486,\n",
            "         -0.0567, -0.0727,  0.0198,  0.0406, -0.0455,  0.0351,  0.0699, -0.0147,\n",
            "         -0.0916,  0.0071, -0.0787,  0.0104,  0.0919,  0.0967, -0.0705, -0.0446,\n",
            "         -0.0999,  0.0775,  0.0002,  0.0765, -0.0446, -0.1071,  0.0981, -0.0867,\n",
            "         -0.0378, -0.0567,  0.0892, -0.0800,  0.0085, -0.0079, -0.0806,  0.0818,\n",
            "         -0.0899, -0.0916, -0.0418,  0.0901, -0.0658, -0.0798, -0.0835,  0.0512,\n",
            "         -0.0880, -0.0588,  0.0671,  0.0674, -0.0424, -0.1078, -0.0036,  0.0132,\n",
            "          0.0475,  0.0616, -0.0561,  0.0083, -0.0335, -0.0266, -0.0929,  0.0107,\n",
            "          0.0272,  0.1039, -0.0610,  0.0965, -0.0380, -0.0371,  0.0014,  0.0928,\n",
            "         -0.0829,  0.1025,  0.1071,  0.0143, -0.0941,  0.0518,  0.1090, -0.1054,\n",
            "          0.0233, -0.0509,  0.0588,  0.0596]])\n",
            "tensor([-0.0689, -0.0910,  0.0970,  0.0340, -0.0320, -0.1089, -0.0291,  0.0461,\n",
            "        -0.0832,  0.0534])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ao2PqkME5orf"
      },
      "source": [
        "#完整的流程\n",
        "import torch.optim as optim\n",
        "optimizer = optim.SGD(net.parameters(),learning_rate)\n",
        "\n",
        "optimizer.zero_grad()\n",
        "#清除梯度缓存\n",
        "output = net(input)\n",
        "loss = criterion(output,target)#计算损失函数\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "#更新参数"
      ],
      "execution_count": 35,
      "outputs": []
    }
  ]
}